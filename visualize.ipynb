{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Average</th>\n",
       "      <th>Roleplay Adherence</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Contextual Understanding</th>\n",
       "      <th>Expressiveness</th>\n",
       "      <th>Creativity</th>\n",
       "      <th>Naturalness of Japanese</th>\n",
       "      <th>Enjoyment of the Dialogue</th>\n",
       "      <th>Appropriateness of Turn-Taking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <td>4.403</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.792</td>\n",
       "      <td>4.625</td>\n",
       "      <td>4.092</td>\n",
       "      <td>3.833</td>\n",
       "      <td>4.800</td>\n",
       "      <td>4.083</td>\n",
       "      <td>4.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <td>4.397</td>\n",
       "      <td>4.592</td>\n",
       "      <td>4.708</td>\n",
       "      <td>4.617</td>\n",
       "      <td>4.025</td>\n",
       "      <td>3.967</td>\n",
       "      <td>4.742</td>\n",
       "      <td>4.117</td>\n",
       "      <td>4.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-2024-07-18</th>\n",
       "      <td>4.324</td>\n",
       "      <td>4.692</td>\n",
       "      <td>4.708</td>\n",
       "      <td>4.575</td>\n",
       "      <td>3.883</td>\n",
       "      <td>3.642</td>\n",
       "      <td>4.717</td>\n",
       "      <td>3.850</td>\n",
       "      <td>4.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-pro-002</th>\n",
       "      <td>4.268</td>\n",
       "      <td>4.633</td>\n",
       "      <td>4.683</td>\n",
       "      <td>4.467</td>\n",
       "      <td>3.858</td>\n",
       "      <td>3.658</td>\n",
       "      <td>4.658</td>\n",
       "      <td>3.817</td>\n",
       "      <td>4.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyberagent/Mistral-Nemo-Japanese-Instruct-2408</th>\n",
       "      <td>4.266</td>\n",
       "      <td>4.508</td>\n",
       "      <td>4.642</td>\n",
       "      <td>4.533</td>\n",
       "      <td>3.850</td>\n",
       "      <td>3.658</td>\n",
       "      <td>4.675</td>\n",
       "      <td>3.892</td>\n",
       "      <td>4.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <td>4.242</td>\n",
       "      <td>4.617</td>\n",
       "      <td>4.642</td>\n",
       "      <td>4.500</td>\n",
       "      <td>3.750</td>\n",
       "      <td>3.542</td>\n",
       "      <td>4.708</td>\n",
       "      <td>3.750</td>\n",
       "      <td>4.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>command-r-plus-08-2024</th>\n",
       "      <td>4.216</td>\n",
       "      <td>4.617</td>\n",
       "      <td>4.633</td>\n",
       "      <td>4.425</td>\n",
       "      <td>3.708</td>\n",
       "      <td>3.550</td>\n",
       "      <td>4.650</td>\n",
       "      <td>3.733</td>\n",
       "      <td>4.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen2.5-72B-Instruct</th>\n",
       "      <td>4.206</td>\n",
       "      <td>4.658</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.458</td>\n",
       "      <td>3.725</td>\n",
       "      <td>3.533</td>\n",
       "      <td>4.608</td>\n",
       "      <td>3.692</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-pro</th>\n",
       "      <td>4.203</td>\n",
       "      <td>4.475</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.425</td>\n",
       "      <td>3.775</td>\n",
       "      <td>3.558</td>\n",
       "      <td>4.650</td>\n",
       "      <td>3.725</td>\n",
       "      <td>4.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-preview-2024-09-12</th>\n",
       "      <td>4.179</td>\n",
       "      <td>4.625</td>\n",
       "      <td>4.650</td>\n",
       "      <td>4.383</td>\n",
       "      <td>3.642</td>\n",
       "      <td>3.417</td>\n",
       "      <td>4.600</td>\n",
       "      <td>3.617</td>\n",
       "      <td>4.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-flash-002</th>\n",
       "      <td>4.162</td>\n",
       "      <td>4.675</td>\n",
       "      <td>4.633</td>\n",
       "      <td>4.333</td>\n",
       "      <td>3.683</td>\n",
       "      <td>3.400</td>\n",
       "      <td>4.542</td>\n",
       "      <td>3.633</td>\n",
       "      <td>4.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku-20240307</th>\n",
       "      <td>4.150</td>\n",
       "      <td>4.350</td>\n",
       "      <td>4.608</td>\n",
       "      <td>4.358</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.483</td>\n",
       "      <td>4.608</td>\n",
       "      <td>3.708</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen2.5-32B-Instruct</th>\n",
       "      <td>4.132</td>\n",
       "      <td>4.525</td>\n",
       "      <td>4.617</td>\n",
       "      <td>4.408</td>\n",
       "      <td>3.650</td>\n",
       "      <td>3.450</td>\n",
       "      <td>4.508</td>\n",
       "      <td>3.533</td>\n",
       "      <td>4.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-mini-2024-09-12</th>\n",
       "      <td>4.117</td>\n",
       "      <td>4.675</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.367</td>\n",
       "      <td>3.475</td>\n",
       "      <td>3.392</td>\n",
       "      <td>4.583</td>\n",
       "      <td>3.525</td>\n",
       "      <td>4.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-large-2407</th>\n",
       "      <td>4.114</td>\n",
       "      <td>4.642</td>\n",
       "      <td>4.617</td>\n",
       "      <td>4.367</td>\n",
       "      <td>3.525</td>\n",
       "      <td>3.325</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3.558</td>\n",
       "      <td>4.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyberagent/calm3-22b-chat</th>\n",
       "      <td>4.085</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4.583</td>\n",
       "      <td>4.350</td>\n",
       "      <td>3.583</td>\n",
       "      <td>3.475</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3.600</td>\n",
       "      <td>4.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-2-27b-it</th>\n",
       "      <td>4.060</td>\n",
       "      <td>4.442</td>\n",
       "      <td>4.575</td>\n",
       "      <td>4.275</td>\n",
       "      <td>3.567</td>\n",
       "      <td>3.392</td>\n",
       "      <td>4.542</td>\n",
       "      <td>3.542</td>\n",
       "      <td>4.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyberagent/Llama-3.1-70B-Japanese-Instruct-2407</th>\n",
       "      <td>4.052</td>\n",
       "      <td>4.283</td>\n",
       "      <td>4.583</td>\n",
       "      <td>4.300</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.450</td>\n",
       "      <td>4.425</td>\n",
       "      <td>3.600</td>\n",
       "      <td>4.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aratako/calm3-22b-RP-v2</th>\n",
       "      <td>4.045</td>\n",
       "      <td>4.358</td>\n",
       "      <td>4.550</td>\n",
       "      <td>4.225</td>\n",
       "      <td>3.600</td>\n",
       "      <td>3.342</td>\n",
       "      <td>4.517</td>\n",
       "      <td>3.592</td>\n",
       "      <td>4.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>command-r-08-2024</th>\n",
       "      <td>4.038</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4.567</td>\n",
       "      <td>4.258</td>\n",
       "      <td>3.550</td>\n",
       "      <td>3.308</td>\n",
       "      <td>4.508</td>\n",
       "      <td>3.567</td>\n",
       "      <td>4.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Meta-Llama-3.1-405B-Instruct</th>\n",
       "      <td>3.975</td>\n",
       "      <td>4.408</td>\n",
       "      <td>4.500</td>\n",
       "      <td>4.258</td>\n",
       "      <td>3.483</td>\n",
       "      <td>3.250</td>\n",
       "      <td>4.367</td>\n",
       "      <td>3.442</td>\n",
       "      <td>4.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-1.5-flash</th>\n",
       "      <td>3.880</td>\n",
       "      <td>4.467</td>\n",
       "      <td>4.467</td>\n",
       "      <td>4.075</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.192</td>\n",
       "      <td>4.183</td>\n",
       "      <td>3.325</td>\n",
       "      <td>3.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>3.794</td>\n",
       "      <td>4.308</td>\n",
       "      <td>4.383</td>\n",
       "      <td>4.008</td>\n",
       "      <td>3.308</td>\n",
       "      <td>2.992</td>\n",
       "      <td>4.333</td>\n",
       "      <td>3.150</td>\n",
       "      <td>3.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-Small-Instruct-2409</th>\n",
       "      <td>3.749</td>\n",
       "      <td>4.225</td>\n",
       "      <td>4.350</td>\n",
       "      <td>3.967</td>\n",
       "      <td>3.258</td>\n",
       "      <td>2.942</td>\n",
       "      <td>4.083</td>\n",
       "      <td>3.192</td>\n",
       "      <td>3.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weblab-GENIAC/Tanuki-8B-dpo-v1.0</th>\n",
       "      <td>3.695</td>\n",
       "      <td>3.817</td>\n",
       "      <td>4.100</td>\n",
       "      <td>3.983</td>\n",
       "      <td>3.317</td>\n",
       "      <td>3.233</td>\n",
       "      <td>4.183</td>\n",
       "      <td>3.308</td>\n",
       "      <td>3.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nitky/Oumuamua-7b-instruct-v2</th>\n",
       "      <td>3.686</td>\n",
       "      <td>3.742</td>\n",
       "      <td>4.242</td>\n",
       "      <td>3.958</td>\n",
       "      <td>3.325</td>\n",
       "      <td>3.067</td>\n",
       "      <td>4.150</td>\n",
       "      <td>3.275</td>\n",
       "      <td>3.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elyza/Llama-3-ELYZA-JP-8B</th>\n",
       "      <td>3.673</td>\n",
       "      <td>4.200</td>\n",
       "      <td>4.408</td>\n",
       "      <td>3.817</td>\n",
       "      <td>3.067</td>\n",
       "      <td>2.858</td>\n",
       "      <td>4.217</td>\n",
       "      <td>3.108</td>\n",
       "      <td>3.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen/Qwen2.5-7B-Instruct</th>\n",
       "      <td>3.661</td>\n",
       "      <td>3.867</td>\n",
       "      <td>4.175</td>\n",
       "      <td>3.975</td>\n",
       "      <td>3.275</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.983</td>\n",
       "      <td>3.200</td>\n",
       "      <td>3.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-Nemo-Instruct-2407</th>\n",
       "      <td>3.535</td>\n",
       "      <td>3.808</td>\n",
       "      <td>4.058</td>\n",
       "      <td>3.842</td>\n",
       "      <td>3.175</td>\n",
       "      <td>3.042</td>\n",
       "      <td>3.433</td>\n",
       "      <td>3.133</td>\n",
       "      <td>3.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Meta-Llama-3.1-70B-Instruct</th>\n",
       "      <td>3.517</td>\n",
       "      <td>4.117</td>\n",
       "      <td>4.208</td>\n",
       "      <td>3.675</td>\n",
       "      <td>2.975</td>\n",
       "      <td>2.708</td>\n",
       "      <td>3.958</td>\n",
       "      <td>2.892</td>\n",
       "      <td>3.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1</th>\n",
       "      <td>3.271</td>\n",
       "      <td>3.800</td>\n",
       "      <td>4.008</td>\n",
       "      <td>3.400</td>\n",
       "      <td>2.717</td>\n",
       "      <td>2.483</td>\n",
       "      <td>3.708</td>\n",
       "      <td>2.642</td>\n",
       "      <td>3.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Meta-Llama-3.1-8B-Instruct</th>\n",
       "      <td>2.986</td>\n",
       "      <td>3.475</td>\n",
       "      <td>3.775</td>\n",
       "      <td>3.042</td>\n",
       "      <td>2.533</td>\n",
       "      <td>2.250</td>\n",
       "      <td>3.400</td>\n",
       "      <td>2.442</td>\n",
       "      <td>2.967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Overall Average  \\\n",
       "target_model_name                                                  \n",
       "claude-3-opus-20240229                                     4.403   \n",
       "claude-3-5-sonnet-20240620                                 4.397   \n",
       "gpt-4o-mini-2024-07-18                                     4.324   \n",
       "gemini-1.5-pro-002                                         4.268   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408             4.266   \n",
       "gpt-4o-2024-08-06                                          4.242   \n",
       "command-r-plus-08-2024                                     4.216   \n",
       "Qwen/Qwen2.5-72B-Instruct                                  4.206   \n",
       "gemini-1.5-pro                                             4.203   \n",
       "o1-preview-2024-09-12                                      4.179   \n",
       "gemini-1.5-flash-002                                       4.162   \n",
       "claude-3-haiku-20240307                                    4.150   \n",
       "Qwen/Qwen2.5-32B-Instruct                                  4.132   \n",
       "o1-mini-2024-09-12                                         4.117   \n",
       "mistral-large-2407                                         4.114   \n",
       "cyberagent/calm3-22b-chat                                  4.085   \n",
       "google/gemma-2-27b-it                                      4.060   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407            4.052   \n",
       "Aratako/calm3-22b-RP-v2                                    4.045   \n",
       "command-r-08-2024                                          4.038   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                    3.975   \n",
       "gemini-1.5-flash                                           3.880   \n",
       "deepseek-chat                                              3.794   \n",
       "mistralai/Mistral-Small-Instruct-2409                      3.749   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                           3.695   \n",
       "nitky/Oumuamua-7b-instruct-v2                              3.686   \n",
       "elyza/Llama-3-ELYZA-JP-8B                                  3.673   \n",
       "Qwen/Qwen2.5-7B-Instruct                                   3.661   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                       3.535   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                     3.517   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1             3.271   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                      2.986   \n",
       "\n",
       "                                                 Roleplay Adherence  \\\n",
       "target_model_name                                                     \n",
       "claude-3-opus-20240229                                        4.600   \n",
       "claude-3-5-sonnet-20240620                                    4.592   \n",
       "gpt-4o-mini-2024-07-18                                        4.692   \n",
       "gemini-1.5-pro-002                                            4.633   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408                4.508   \n",
       "gpt-4o-2024-08-06                                             4.617   \n",
       "command-r-plus-08-2024                                        4.617   \n",
       "Qwen/Qwen2.5-72B-Instruct                                     4.658   \n",
       "gemini-1.5-pro                                                4.475   \n",
       "o1-preview-2024-09-12                                         4.625   \n",
       "gemini-1.5-flash-002                                          4.675   \n",
       "claude-3-haiku-20240307                                       4.350   \n",
       "Qwen/Qwen2.5-32B-Instruct                                     4.525   \n",
       "o1-mini-2024-09-12                                            4.675   \n",
       "mistral-large-2407                                            4.642   \n",
       "cyberagent/calm3-22b-chat                                     4.400   \n",
       "google/gemma-2-27b-it                                         4.442   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407               4.283   \n",
       "Aratako/calm3-22b-RP-v2                                       4.358   \n",
       "command-r-08-2024                                             4.400   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                       4.408   \n",
       "gemini-1.5-flash                                              4.467   \n",
       "deepseek-chat                                                 4.308   \n",
       "mistralai/Mistral-Small-Instruct-2409                         4.225   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                              3.817   \n",
       "nitky/Oumuamua-7b-instruct-v2                                 3.742   \n",
       "elyza/Llama-3-ELYZA-JP-8B                                     4.200   \n",
       "Qwen/Qwen2.5-7B-Instruct                                      3.867   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                          3.808   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                        4.117   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1                3.800   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                         3.475   \n",
       "\n",
       "                                                 Consistency  \\\n",
       "target_model_name                                              \n",
       "claude-3-opus-20240229                                 4.792   \n",
       "claude-3-5-sonnet-20240620                             4.708   \n",
       "gpt-4o-mini-2024-07-18                                 4.708   \n",
       "gemini-1.5-pro-002                                     4.683   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408         4.642   \n",
       "gpt-4o-2024-08-06                                      4.642   \n",
       "command-r-plus-08-2024                                 4.633   \n",
       "Qwen/Qwen2.5-72B-Instruct                              4.650   \n",
       "gemini-1.5-pro                                         4.600   \n",
       "o1-preview-2024-09-12                                  4.650   \n",
       "gemini-1.5-flash-002                                   4.633   \n",
       "claude-3-haiku-20240307                                4.608   \n",
       "Qwen/Qwen2.5-32B-Instruct                              4.617   \n",
       "o1-mini-2024-09-12                                     4.600   \n",
       "mistral-large-2407                                     4.617   \n",
       "cyberagent/calm3-22b-chat                              4.583   \n",
       "google/gemma-2-27b-it                                  4.575   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407        4.583   \n",
       "Aratako/calm3-22b-RP-v2                                4.550   \n",
       "command-r-08-2024                                      4.567   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                4.500   \n",
       "gemini-1.5-flash                                       4.467   \n",
       "deepseek-chat                                          4.383   \n",
       "mistralai/Mistral-Small-Instruct-2409                  4.350   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                       4.100   \n",
       "nitky/Oumuamua-7b-instruct-v2                          4.242   \n",
       "elyza/Llama-3-ELYZA-JP-8B                              4.408   \n",
       "Qwen/Qwen2.5-7B-Instruct                               4.175   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                   4.058   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                 4.208   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1         4.008   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                  3.775   \n",
       "\n",
       "                                                 Contextual Understanding  \\\n",
       "target_model_name                                                           \n",
       "claude-3-opus-20240229                                              4.625   \n",
       "claude-3-5-sonnet-20240620                                          4.617   \n",
       "gpt-4o-mini-2024-07-18                                              4.575   \n",
       "gemini-1.5-pro-002                                                  4.467   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408                      4.533   \n",
       "gpt-4o-2024-08-06                                                   4.500   \n",
       "command-r-plus-08-2024                                              4.425   \n",
       "Qwen/Qwen2.5-72B-Instruct                                           4.458   \n",
       "gemini-1.5-pro                                                      4.425   \n",
       "o1-preview-2024-09-12                                               4.383   \n",
       "gemini-1.5-flash-002                                                4.333   \n",
       "claude-3-haiku-20240307                                             4.358   \n",
       "Qwen/Qwen2.5-32B-Instruct                                           4.408   \n",
       "o1-mini-2024-09-12                                                  4.367   \n",
       "mistral-large-2407                                                  4.367   \n",
       "cyberagent/calm3-22b-chat                                           4.350   \n",
       "google/gemma-2-27b-it                                               4.275   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407                     4.300   \n",
       "Aratako/calm3-22b-RP-v2                                             4.225   \n",
       "command-r-08-2024                                                   4.258   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                             4.258   \n",
       "gemini-1.5-flash                                                    4.075   \n",
       "deepseek-chat                                                       4.008   \n",
       "mistralai/Mistral-Small-Instruct-2409                               3.967   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                                    3.983   \n",
       "nitky/Oumuamua-7b-instruct-v2                                       3.958   \n",
       "elyza/Llama-3-ELYZA-JP-8B                                           3.817   \n",
       "Qwen/Qwen2.5-7B-Instruct                                            3.975   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                                3.842   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                              3.675   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1                      3.400   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                               3.042   \n",
       "\n",
       "                                                 Expressiveness  Creativity  \\\n",
       "target_model_name                                                             \n",
       "claude-3-opus-20240229                                    4.092       3.833   \n",
       "claude-3-5-sonnet-20240620                                4.025       3.967   \n",
       "gpt-4o-mini-2024-07-18                                    3.883       3.642   \n",
       "gemini-1.5-pro-002                                        3.858       3.658   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408            3.850       3.658   \n",
       "gpt-4o-2024-08-06                                         3.750       3.542   \n",
       "command-r-plus-08-2024                                    3.708       3.550   \n",
       "Qwen/Qwen2.5-72B-Instruct                                 3.725       3.533   \n",
       "gemini-1.5-pro                                            3.775       3.558   \n",
       "o1-preview-2024-09-12                                     3.642       3.417   \n",
       "gemini-1.5-flash-002                                      3.683       3.400   \n",
       "claude-3-haiku-20240307                                   3.800       3.483   \n",
       "Qwen/Qwen2.5-32B-Instruct                                 3.650       3.450   \n",
       "o1-mini-2024-09-12                                        3.475       3.392   \n",
       "mistral-large-2407                                        3.525       3.325   \n",
       "cyberagent/calm3-22b-chat                                 3.583       3.475   \n",
       "google/gemma-2-27b-it                                     3.567       3.392   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407           3.625       3.450   \n",
       "Aratako/calm3-22b-RP-v2                                   3.600       3.342   \n",
       "command-r-08-2024                                         3.550       3.308   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                   3.483       3.250   \n",
       "gemini-1.5-flash                                          3.400       3.192   \n",
       "deepseek-chat                                             3.308       2.992   \n",
       "mistralai/Mistral-Small-Instruct-2409                     3.258       2.942   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                          3.317       3.233   \n",
       "nitky/Oumuamua-7b-instruct-v2                             3.325       3.067   \n",
       "elyza/Llama-3-ELYZA-JP-8B                                 3.067       2.858   \n",
       "Qwen/Qwen2.5-7B-Instruct                                  3.275       3.008   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                      3.175       3.042   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                    2.975       2.708   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1            2.717       2.483   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                     2.533       2.250   \n",
       "\n",
       "                                                 Naturalness of Japanese  \\\n",
       "target_model_name                                                          \n",
       "claude-3-opus-20240229                                             4.800   \n",
       "claude-3-5-sonnet-20240620                                         4.742   \n",
       "gpt-4o-mini-2024-07-18                                             4.717   \n",
       "gemini-1.5-pro-002                                                 4.658   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408                     4.675   \n",
       "gpt-4o-2024-08-06                                                  4.708   \n",
       "command-r-plus-08-2024                                             4.650   \n",
       "Qwen/Qwen2.5-72B-Instruct                                          4.608   \n",
       "gemini-1.5-pro                                                     4.650   \n",
       "o1-preview-2024-09-12                                              4.600   \n",
       "gemini-1.5-flash-002                                               4.542   \n",
       "claude-3-haiku-20240307                                            4.608   \n",
       "Qwen/Qwen2.5-32B-Instruct                                          4.508   \n",
       "o1-mini-2024-09-12                                                 4.583   \n",
       "mistral-large-2407                                                 4.550   \n",
       "cyberagent/calm3-22b-chat                                          4.550   \n",
       "google/gemma-2-27b-it                                              4.542   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407                    4.425   \n",
       "Aratako/calm3-22b-RP-v2                                            4.517   \n",
       "command-r-08-2024                                                  4.508   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                            4.367   \n",
       "gemini-1.5-flash                                                   4.183   \n",
       "deepseek-chat                                                      4.333   \n",
       "mistralai/Mistral-Small-Instruct-2409                              4.083   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                                   4.183   \n",
       "nitky/Oumuamua-7b-instruct-v2                                      4.150   \n",
       "elyza/Llama-3-ELYZA-JP-8B                                          4.217   \n",
       "Qwen/Qwen2.5-7B-Instruct                                           3.983   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                               3.433   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                             3.958   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1                     3.708   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                              3.400   \n",
       "\n",
       "                                                 Enjoyment of the Dialogue  \\\n",
       "target_model_name                                                            \n",
       "claude-3-opus-20240229                                               4.083   \n",
       "claude-3-5-sonnet-20240620                                           4.117   \n",
       "gpt-4o-mini-2024-07-18                                               3.850   \n",
       "gemini-1.5-pro-002                                                   3.817   \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408                       3.892   \n",
       "gpt-4o-2024-08-06                                                    3.750   \n",
       "command-r-plus-08-2024                                               3.733   \n",
       "Qwen/Qwen2.5-72B-Instruct                                            3.692   \n",
       "gemini-1.5-pro                                                       3.725   \n",
       "o1-preview-2024-09-12                                                3.617   \n",
       "gemini-1.5-flash-002                                                 3.633   \n",
       "claude-3-haiku-20240307                                              3.708   \n",
       "Qwen/Qwen2.5-32B-Instruct                                            3.533   \n",
       "o1-mini-2024-09-12                                                   3.525   \n",
       "mistral-large-2407                                                   3.558   \n",
       "cyberagent/calm3-22b-chat                                            3.600   \n",
       "google/gemma-2-27b-it                                                3.542   \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407                      3.600   \n",
       "Aratako/calm3-22b-RP-v2                                              3.592   \n",
       "command-r-08-2024                                                    3.567   \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                              3.442   \n",
       "gemini-1.5-flash                                                     3.325   \n",
       "deepseek-chat                                                        3.150   \n",
       "mistralai/Mistral-Small-Instruct-2409                                3.192   \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                                     3.308   \n",
       "nitky/Oumuamua-7b-instruct-v2                                        3.275   \n",
       "elyza/Llama-3-ELYZA-JP-8B                                            3.108   \n",
       "Qwen/Qwen2.5-7B-Instruct                                             3.200   \n",
       "mistralai/Mistral-Nemo-Instruct-2407                                 3.133   \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                               2.892   \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1                       2.642   \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                                2.442   \n",
       "\n",
       "                                                 Appropriateness of Turn-Taking  \n",
       "target_model_name                                                                \n",
       "claude-3-opus-20240229                                                    4.400  \n",
       "claude-3-5-sonnet-20240620                                                4.408  \n",
       "gpt-4o-mini-2024-07-18                                                    4.525  \n",
       "gemini-1.5-pro-002                                                        4.367  \n",
       "cyberagent/Mistral-Nemo-Japanese-Instruct-2408                            4.367  \n",
       "gpt-4o-2024-08-06                                                         4.425  \n",
       "command-r-plus-08-2024                                                    4.408  \n",
       "Qwen/Qwen2.5-72B-Instruct                                                 4.325  \n",
       "gemini-1.5-pro                                                            4.417  \n",
       "o1-preview-2024-09-12                                                     4.500  \n",
       "gemini-1.5-flash-002                                                      4.400  \n",
       "claude-3-haiku-20240307                                                   4.283  \n",
       "Qwen/Qwen2.5-32B-Instruct                                                 4.367  \n",
       "o1-mini-2024-09-12                                                        4.317  \n",
       "mistral-large-2407                                                        4.325  \n",
       "cyberagent/calm3-22b-chat                                                 4.142  \n",
       "google/gemma-2-27b-it                                                     4.142  \n",
       "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407                           4.150  \n",
       "Aratako/calm3-22b-RP-v2                                                   4.175  \n",
       "command-r-08-2024                                                         4.150  \n",
       "meta-llama/Meta-Llama-3.1-405B-Instruct                                   4.092  \n",
       "gemini-1.5-flash                                                          3.933  \n",
       "deepseek-chat                                                             3.867  \n",
       "mistralai/Mistral-Small-Instruct-2409                                     3.975  \n",
       "weblab-GENIAC/Tanuki-8B-dpo-v1.0                                          3.617  \n",
       "nitky/Oumuamua-7b-instruct-v2                                             3.733  \n",
       "elyza/Llama-3-ELYZA-JP-8B                                                 3.708  \n",
       "Qwen/Qwen2.5-7B-Instruct                                                  3.808  \n",
       "mistralai/Mistral-Nemo-Instruct-2407                                      3.792  \n",
       "meta-llama/Meta-Llama-3.1-70B-Instruct                                    3.600  \n",
       "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1                            3.408  \n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct                                     2.967  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スコアを降順でまとめて表示\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_jsonl_files_from_directory(directory_path):\n",
    "    # Get all jsonl files in the directory\n",
    "    jsonl_files = [f for f in os.listdir(directory_path) if f.endswith(\".jsonl\")]\n",
    "\n",
    "    # Read all jsonl files into a list of DataFrames\n",
    "    dataframes = []\n",
    "    for jsonl_file in jsonl_files:\n",
    "        file_path = os.path.join(directory_path, jsonl_file)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "            data = [json.loads(line) for line in lines]\n",
    "            df = pd.DataFrame(data)\n",
    "            dataframes.append(df)\n",
    "\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def calculate_and_display_scores(combined_df):\n",
    "    # Relevant columns for calculating scores\n",
    "    score_columns = [\n",
    "        \"Roleplay Adherence\",\n",
    "        \"Consistency\",\n",
    "        \"Contextual Understanding\",\n",
    "        \"Expressiveness\",\n",
    "        \"Creativity\",\n",
    "        \"Naturalness of Japanese\",\n",
    "        \"Enjoyment of the Dialogue\",\n",
    "        \"Appropriateness of Turn-Taking\",\n",
    "    ]\n",
    "\n",
    "    # Group by 'target_model_name' and calculate the average for each score category\n",
    "    avg_scores_by_model = round(combined_df.groupby(\"target_model_name\")[score_columns].mean(), 3)\n",
    "\n",
    "    # Calculate the overall average score per model\n",
    "    avg_scores_by_model[\"Overall Average\"] = round(avg_scores_by_model.mean(axis=1), 3)\n",
    "\n",
    "    cols = [\"Overall Average\"] + [col for col in avg_scores_by_model.columns if col != \"Overall Average\"]\n",
    "    avg_scores_by_model = avg_scores_by_model[cols]\n",
    "\n",
    "    # Sort the table by 'Overall Average' in descending order\n",
    "    avg_scores_by_model_sorted = avg_scores_by_model.sort_values(\n",
    "        by=\"Overall Average\", ascending=False\n",
    "    )\n",
    "\n",
    "    # Display the resulting table\n",
    "    # print(avg_scores_by_model_sorted)\n",
    "    return avg_scores_by_model_sorted\n",
    "\n",
    "\n",
    "# Directory path containing the jsonl files\n",
    "directory_path = \"./evaluations\"\n",
    "\n",
    "# Load all JSONL files from the directory\n",
    "combined_df = load_jsonl_files_from_directory(directory_path)\n",
    "\n",
    "# Calculate and display the scores sorted by overall average\n",
    "scores = calculate_and_display_scores(combined_df)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall</th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>o1-mini-2024-09-12</th>\n",
       "      <th>anthropic.claude-3-5-sonnet-20240620-v1:0</th>\n",
       "      <th>gemini-1.5-pro-002</th>\n",
       "      <th>gpt-4o-2024-08-06_o1-mini-2024-09-12</th>\n",
       "      <th>gpt-4o-2024-08-06_anthropic.claude-3-5-sonnet-20240620-v1:0</th>\n",
       "      <th>gpt-4o-2024-08-06_gemini-1.5-pro-002</th>\n",
       "      <th>o1-mini-2024-09-12_anthropic.claude-3-5-sonnet-20240620-v1:0</th>\n",
       "      <th>o1-mini-2024-09-12_gemini-1.5-pro-002</th>\n",
       "      <th>anthropic.claude-3-5-sonnet-20240620-v1:0_gemini-1.5-pro-002</th>\n",
       "      <th>gpt-4o-2024-08-06_o1-mini-2024-09-12_anthropic.claude-3-5-sonnet-20240620-v1:0</th>\n",
       "      <th>gpt-4o-2024-08-06_o1-mini-2024-09-12_gemini-1.5-pro-002</th>\n",
       "      <th>gpt-4o-2024-08-06_anthropic.claude-3-5-sonnet-20240620-v1:0_gemini-1.5-pro-002</th>\n",
       "      <th>o1-mini-2024-09-12_anthropic.claude-3-5-sonnet-20240620-v1:0_gemini-1.5-pro-002</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Roleplay Adherence</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Understanding</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expressiveness</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creativity</th>\n",
       "      <td>0.430</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naturalness of Japanese</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enjoyment of the Dialogue</th>\n",
       "      <td>0.504</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appropriateness of Turn-Taking</th>\n",
       "      <td>0.617</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Score</th>\n",
       "      <td>0.601</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Overall  gpt-4o-2024-08-06  \\\n",
       "Roleplay Adherence                0.632              0.473   \n",
       "Consistency                       0.520              0.576   \n",
       "Contextual Understanding          0.526              0.416   \n",
       "Expressiveness                    0.560              0.391   \n",
       "Creativity                        0.430              0.347   \n",
       "Naturalness of Japanese           0.555              0.484   \n",
       "Enjoyment of the Dialogue         0.504              0.200   \n",
       "Appropriateness of Turn-Taking    0.617              0.531   \n",
       "Average Score                     0.601              0.426   \n",
       "\n",
       "                                o1-mini-2024-09-12  \\\n",
       "Roleplay Adherence                           0.460   \n",
       "Consistency                                  0.501   \n",
       "Contextual Understanding                     0.525   \n",
       "Expressiveness                               0.477   \n",
       "Creativity                                   0.294   \n",
       "Naturalness of Japanese                      0.566   \n",
       "Enjoyment of the Dialogue                    0.438   \n",
       "Appropriateness of Turn-Taking               0.288   \n",
       "Average Score                                0.463   \n",
       "\n",
       "                                anthropic.claude-3-5-sonnet-20240620-v1:0  \\\n",
       "Roleplay Adherence                                                  0.290   \n",
       "Consistency                                                         0.195   \n",
       "Contextual Understanding                                            0.309   \n",
       "Expressiveness                                                      0.420   \n",
       "Creativity                                                          0.396   \n",
       "Naturalness of Japanese                                             0.386   \n",
       "Enjoyment of the Dialogue                                           0.481   \n",
       "Appropriateness of Turn-Taking                                      0.488   \n",
       "Average Score                                                       0.427   \n",
       "\n",
       "                                gemini-1.5-pro-002  \\\n",
       "Roleplay Adherence                           0.540   \n",
       "Consistency                                  0.446   \n",
       "Contextual Understanding                     0.484   \n",
       "Expressiveness                               0.470   \n",
       "Creativity                                   0.462   \n",
       "Naturalness of Japanese                      0.548   \n",
       "Enjoyment of the Dialogue                    0.443   \n",
       "Appropriateness of Turn-Taking               0.361   \n",
       "Average Score                                0.554   \n",
       "\n",
       "                                gpt-4o-2024-08-06_o1-mini-2024-09-12  \\\n",
       "Roleplay Adherence                                             0.604   \n",
       "Consistency                                                    0.641   \n",
       "Contextual Understanding                                       0.556   \n",
       "Expressiveness                                                 0.519   \n",
       "Creativity                                                     0.374   \n",
       "Naturalness of Japanese                                        0.560   \n",
       "Enjoyment of the Dialogue                                      0.399   \n",
       "Appropriateness of Turn-Taking                                 0.485   \n",
       "Average Score                                                  0.547   \n",
       "\n",
       "                                gpt-4o-2024-08-06_anthropic.claude-3-5-sonnet-20240620-v1:0  \\\n",
       "Roleplay Adherence                                                          0.392             \n",
       "Consistency                                                                 0.412             \n",
       "Contextual Understanding                                                    0.393             \n",
       "Expressiveness                                                              0.494             \n",
       "Creativity                                                                  0.420             \n",
       "Naturalness of Japanese                                                     0.494             \n",
       "Enjoyment of the Dialogue                                                   0.437             \n",
       "Appropriateness of Turn-Taking                                              0.604             \n",
       "Average Score                                                               0.507             \n",
       "\n",
       "                                gpt-4o-2024-08-06_gemini-1.5-pro-002  \\\n",
       "Roleplay Adherence                                             0.619   \n",
       "Consistency                                                    0.566   \n",
       "Contextual Understanding                                       0.498   \n",
       "Expressiveness                                                 0.503   \n",
       "Creativity                                                     0.427   \n",
       "Naturalness of Japanese                                        0.545   \n",
       "Enjoyment of the Dialogue                                      0.376   \n",
       "Appropriateness of Turn-Taking                                 0.573   \n",
       "Average Score                                                  0.564   \n",
       "\n",
       "                                o1-mini-2024-09-12_anthropic.claude-3-5-sonnet-20240620-v1:0  \\\n",
       "Roleplay Adherence                                                          0.479              \n",
       "Consistency                                                                 0.406              \n",
       "Contextual Understanding                                                    0.459              \n",
       "Expressiveness                                                              0.500              \n",
       "Creativity                                                                  0.386              \n",
       "Naturalness of Japanese                                                     0.510              \n",
       "Enjoyment of the Dialogue                                                   0.525              \n",
       "Appropriateness of Turn-Taking                                              0.450              \n",
       "Average Score                                                               0.503              \n",
       "\n",
       "                                o1-mini-2024-09-12_gemini-1.5-pro-002  \\\n",
       "Roleplay Adherence                                              0.630   \n",
       "Consistency                                                     0.491   \n",
       "Contextual Understanding                                        0.563   \n",
       "Expressiveness                                                  0.517   \n",
       "Creativity                                                      0.384   \n",
       "Naturalness of Japanese                                         0.564   \n",
       "Enjoyment of the Dialogue                                       0.475   \n",
       "Appropriateness of Turn-Taking                                  0.384   \n",
       "Average Score                                                   0.560   \n",
       "\n",
       "                                anthropic.claude-3-5-sonnet-20240620-v1:0_gemini-1.5-pro-002  \\\n",
       "Roleplay Adherence                                                          0.464              \n",
       "Consistency                                                                 0.287              \n",
       "Contextual Understanding                                                    0.403              \n",
       "Expressiveness                                                              0.474              \n",
       "Creativity                                                                  0.422              \n",
       "Naturalness of Japanese                                                     0.515              \n",
       "Enjoyment of the Dialogue                                                   0.498              \n",
       "Appropriateness of Turn-Taking                                              0.491              \n",
       "Average Score                                                               0.517              \n",
       "\n",
       "                                gpt-4o-2024-08-06_o1-mini-2024-09-12_anthropic.claude-3-5-sonnet-20240620-v1:0  \\\n",
       "Roleplay Adherence                                                          0.579                                \n",
       "Consistency                                                                 0.554                                \n",
       "Contextual Understanding                                                    0.507                                \n",
       "Expressiveness                                                              0.550                                \n",
       "Creativity                                                                  0.406                                \n",
       "Naturalness of Japanese                                                     0.541                                \n",
       "Enjoyment of the Dialogue                                                   0.507                                \n",
       "Appropriateness of Turn-Taking                                              0.577                                \n",
       "Average Score                                                               0.567                                \n",
       "\n",
       "                                gpt-4o-2024-08-06_o1-mini-2024-09-12_gemini-1.5-pro-002  \\\n",
       "Roleplay Adherence                                                          0.684         \n",
       "Consistency                                                                 0.613         \n",
       "Contextual Understanding                                                    0.586         \n",
       "Expressiveness                                                              0.555         \n",
       "Creativity                                                                  0.408         \n",
       "Naturalness of Japanese                                                     0.566         \n",
       "Enjoyment of the Dialogue                                                   0.442         \n",
       "Appropriateness of Turn-Taking                                              0.564         \n",
       "Average Score                                                               0.599         \n",
       "\n",
       "                                gpt-4o-2024-08-06_anthropic.claude-3-5-sonnet-20240620-v1:0_gemini-1.5-pro-002  \\\n",
       "Roleplay Adherence                                                          0.522                                \n",
       "Consistency                                                                 0.435                                \n",
       "Contextual Understanding                                                    0.450                                \n",
       "Expressiveness                                                              0.521                                \n",
       "Creativity                                                                  0.442                                \n",
       "Naturalness of Japanese                                                     0.545                                \n",
       "Enjoyment of the Dialogue                                                   0.463                                \n",
       "Appropriateness of Turn-Taking                                              0.635                                \n",
       "Average Score                                                               0.554                                \n",
       "\n",
       "                                o1-mini-2024-09-12_anthropic.claude-3-5-sonnet-20240620-v1:0_gemini-1.5-pro-002  \n",
       "Roleplay Adherence                                                          0.578                                \n",
       "Consistency                                                                 0.390                                \n",
       "Contextual Understanding                                                    0.496                                \n",
       "Expressiveness                                                              0.521                                \n",
       "Creativity                                                                  0.401                                \n",
       "Naturalness of Japanese                                                     0.544                                \n",
       "Enjoyment of the Dialogue                                                   0.524                                \n",
       "Appropriateness of Turn-Taking                                              0.482                                \n",
       "Average Score                                                               0.549                                "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 人手評価とのスピアマン順位相関係数を計算して表示\n",
    "# 4つのJudge Modelのスコアについて、単体のスコアとの相関・2モデル平均との相関・3モデル平均との相関・4モデル全体平均との相関を全て表示\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    # Load the JSONL file\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Convert the loaded data into a DataFrame\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Extract relevant columns for human and LLM evaluations\n",
    "    human_scores_cols = [col for col in df.columns if col.startswith(\"human_scores.\")]\n",
    "    llm_scores_cols = [\n",
    "        \"Roleplay Adherence\",\n",
    "        \"Consistency\",\n",
    "        \"Contextual Understanding\",\n",
    "        \"Expressiveness\",\n",
    "        \"Creativity\",\n",
    "        \"Naturalness of Japanese\",\n",
    "        \"Enjoyment of the Dialogue\",\n",
    "        \"Appropriateness of Turn-Taking\",\n",
    "    ]\n",
    "\n",
    "    # Calculate overall Spearman correlation for each metric\n",
    "    overall_correlations = {}\n",
    "    for llm_col, human_col in zip(llm_scores_cols, human_scores_cols):\n",
    "        correlation, _ = spearmanr(df[llm_col], df[human_col])\n",
    "        overall_correlations[llm_col] = round(correlation, 3)\n",
    "\n",
    "    # Extract individual evaluations and calculate correlations for each judge model\n",
    "    individual_evaluations = df[\"individual_evaluations\"].explode().dropna()\n",
    "    individual_evaluations_df = pd.json_normalize(individual_evaluations)\n",
    "\n",
    "    judge_correlations = {}\n",
    "    judge_model_names = individual_evaluations_df[\"judge_model_name\"].unique()\n",
    "\n",
    "    for judge_model_name in judge_model_names:\n",
    "        judge_df = individual_evaluations_df[\n",
    "            individual_evaluations_df[\"judge_model_name\"] == judge_model_name\n",
    "        ]\n",
    "        correlations = {}\n",
    "        for llm_col, human_col in zip(llm_scores_cols, human_scores_cols):\n",
    "            if llm_col in judge_df.columns and human_col in df.columns:\n",
    "                correlation, _ = spearmanr(judge_df[llm_col], df[human_col])\n",
    "                correlations[llm_col] = round(correlation, 3)\n",
    "        judge_correlations[judge_model_name] = correlations\n",
    "\n",
    "    # Combine overall correlations and individual judge correlations into a single DataFrame\n",
    "    correlation_results = pd.DataFrame({\"Overall\": overall_correlations})\n",
    "    for judge_model_name, correlations in judge_correlations.items():\n",
    "        correlation_results[judge_model_name] = pd.Series(correlations)\n",
    "\n",
    "    # Calculate the average score correlations\n",
    "    df[\"human_average_score\"] = df[human_scores_cols].mean(axis=1)\n",
    "    df[\"llm_average_score\"] = df[llm_scores_cols].mean(axis=1)\n",
    "\n",
    "    # Calculate the overall average correlation\n",
    "    overall_average_correlation, _ = spearmanr(\n",
    "        df[\"llm_average_score\"], df[\"human_average_score\"]\n",
    "    )\n",
    "    overall_average_correlation = round(overall_average_correlation, 3)\n",
    "\n",
    "    # Average score correlations for individual judge models\n",
    "    individual_evaluations_df[\"llm_average_score\"] = individual_evaluations_df[\n",
    "        llm_scores_cols\n",
    "    ].mean(axis=1)\n",
    "    average_judge_correlations = {}\n",
    "    for judge_model_name in judge_model_names:\n",
    "        judge_df = individual_evaluations_df[\n",
    "            individual_evaluations_df[\"judge_model_name\"] == judge_model_name\n",
    "        ]\n",
    "        correlation, _ = spearmanr(\n",
    "            judge_df[\"llm_average_score\"], df[\"human_average_score\"]\n",
    "        )\n",
    "        average_judge_correlations[judge_model_name] = round(correlation, 3)\n",
    "\n",
    "    # Add the average correlations to the combined table\n",
    "    correlation_results.loc[\"Average Score\"] = pd.Series(average_judge_correlations)\n",
    "    correlation_results[\"Overall\"] = correlation_results[\"Overall\"].fillna(\n",
    "        overall_average_correlation\n",
    "    )\n",
    "\n",
    "    # Define unique judge models\n",
    "    unique_judge_models = [\n",
    "        \"gpt-4o-2024-08-06\",\n",
    "        \"o1-mini-2024-09-12\",\n",
    "        \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"gemini-1.5-pro-002\",\n",
    "    ]\n",
    "\n",
    "    # Calculate Spearman correlations for all 2-model and 3-model combinations\n",
    "    combination_correlations = {}\n",
    "    for k in [2, 3]:\n",
    "        for comb in combinations(unique_judge_models, k):\n",
    "            comb_name = \"_\".join(comb)\n",
    "            correlations = {}\n",
    "            for score_name in llm_scores_cols:\n",
    "                avg_col_name = f\"averages_{k}_models.avg_{'_'.join(comb)}.{score_name}\"\n",
    "                if avg_col_name in df.columns:\n",
    "                    correlation, _ = spearmanr(\n",
    "                        df[avg_col_name], df[f\"human_scores.{score_name}\"]\n",
    "                    )\n",
    "                    correlations[score_name] = round(correlation, 3)\n",
    "\n",
    "            # Calculate the overall average score correlation for the combination\n",
    "            df[f\"{comb_name}_average_score\"] = df[\n",
    "                [\n",
    "                    f\"averages_{k}_models.avg_{'_'.join(comb)}.{metric}\"\n",
    "                    for metric in llm_scores_cols\n",
    "                ]\n",
    "            ].mean(axis=1)\n",
    "            correlation, _ = spearmanr(\n",
    "                df[f\"{comb_name}_average_score\"], df[\"human_average_score\"]\n",
    "            )\n",
    "            correlations[\"Average Score\"] = round(correlation, 3)\n",
    "\n",
    "            combination_correlations[comb_name] = correlations\n",
    "\n",
    "    # Convert combination correlations to a DataFrame\n",
    "    combination_correlation_results = pd.DataFrame(combination_correlations)\n",
    "\n",
    "    # Combine the original and combination results into a single comprehensive table\n",
    "    final_combined_results = pd.concat(\n",
    "        [correlation_results, combination_correlation_results], axis=1\n",
    "    )\n",
    "\n",
    "    # Display the final comprehensive correlation results\n",
    "    return final_combined_results\n",
    "\n",
    "\n",
    "final_combined_results = process_file(\"./annotated_sample/annotated_sample.jsonl\")\n",
    "final_combined_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
